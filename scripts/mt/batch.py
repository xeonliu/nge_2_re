#!/usr/bin/env python3
"""
æ‰¹é‡ç¿»è¯‘ JSONL æ–‡ä»¶
å°†è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œå¹¶æ·»åŠ  translation å­—æ®µ
"""

import json
import os
from pathlib import Path
from typing import List, Dict, Any
from openai import OpenAI
from pydantic import BaseModel

# é…ç½®
BATCH_SIZE = 5  # æ¯æ‰¹ç¿»è¯‘çš„æ¡ç›®æ•°
INPUT_FILE = "imtext_stage0.json"
OUTPUT_FILE = "imtext_stage0_translated.json"
API_KEY = os.getenv("OPENAI_API_KEY")  # ä»ç¯å¢ƒå˜é‡è¯»å–
API_BASE = os.getenv("OPENAI_API_BASE")  # API Base URLï¼Œå¯é€‰
GLOSSARY_FILE = "terms-10882.json"


class TranslationItem(BaseModel):
    """å•æ¡ç¿»è¯‘ç»“æœ"""
    id: int
    translation: str


class TranslationBatch(BaseModel):
    """æ‰¹é‡ç¿»è¯‘ç»“æœ"""
    translations: List[TranslationItem]


def load_glossary_terms(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½æœ¯è¯­è¡¨ï¼Œä»…ä¿ç•™å¿…è¦å­—æ®µä»¥æ§åˆ¶æç¤ºé•¿åº¦"""
    raw_terms = load_json(file_path)
    glossary = []
    for entry in raw_terms:
        translation = entry.get("translation")
        terms = []
        if entry.get("term"):
            terms.append(entry["term"])
        variants = entry.get("variants") or []
        for variant in variants:
            if variant:
                terms.append(variant)
        if not translation or not terms:
            continue
        glossary.append({
            "terms": terms,
            "translation": translation,
            "caseSensitive": bool(entry.get("caseSensitive", False))
        })
    return glossary


def load_json(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½ JSON æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def save_json(data: List[Dict[str, Any]], file_path: str):
    """ä¿å­˜ä¸º JSON æ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=1)


def translate_batch(client: OpenAI, items: List[Dict[str, Any]], glossary: List[Dict[str, Any]]) -> List[str]:
    """
    æ‰¹é‡ç¿»è¯‘ä¸€æ‰¹æ–‡æœ¬
    
    Args:
        client: OpenAI å®¢æˆ·ç«¯
        items: å¾…ç¿»è¯‘çš„æ¡ç›®åˆ—è¡¨
    
    Returns:
        ç¿»è¯‘ç»“æœåˆ—è¡¨
    """
    # æ„å»ºç¿»è¯‘æç¤º
    texts_to_translate = []
    for item in items:
        texts_to_translate.append({
            "id": item["id"],
            "text": item["original"]
        })
    
        glossary_prompt = ""
        if glossary:
                glossary_prompt = (
                        "è¯·å‚è€ƒä»¥ä¸‹æœ¯è¯­è¡¨ï¼Œé‡åˆ°æœ¯è¯­æˆ–å…¶å˜ä½“æ—¶å¿…é¡»ä½¿ç”¨å¯¹åº”è¯‘å"
                        "ï¼ˆéµå®ˆ caseSensitive æ ‡è®°ï¼‰ï¼š\n"
                        f"{json.dumps(glossary, ensure_ascii=False, indent=2)}\n\n"
                )

        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚è¿™äº›æ˜¯æ¸¸æˆã€Šæ–°ä¸–çºªç¦éŸ³æˆ˜å£«ã€‹çš„å¯¹è¯æ–‡æœ¬ã€‚
è¯·ä»¥è½»å°è¯´çš„é£æ ¼ä¿æŒç¿»è¯‘çš„å‡†ç¡®æ€§å’Œæµç•…æ€§åŒæ—¶å…¼é¡¾è§’è‰²çš„è¯­æ°”ï¼Œç¬¬äºŒäººç§°éç‰¹æ®Šæƒ…å†µä½¿ç”¨â€œä½ â€ï¼Œç¬¦åˆä¸­æ–‡è¡¨è¾¾å’Œæ ‡ç‚¹ä¹ æƒ¯ï¼Œå¦‚çœç•¥å·ä½¿ç”¨â€œâ€¦â€¦â€ ï¼Œè¯­æ°”åœé¡¿ä½¿ç”¨é€—å·ï¼Œå¼•å·ä½¿ç”¨ç›´è§’å¼•å·ã€Œã€ã€‚åŒæ—¶æ³¨æ„ä¿ç•™åŸæœ‰çš„$m, $nç­‰ç‰¹æ®Šæ ‡è®°åŠå…¶æ•°ç›®ä¸å˜ã€‚

{glossary_prompt}å¾…ç¿»è¯‘æ–‡æœ¬ï¼š
{json.dumps(texts_to_translate, ensure_ascii=False, indent=2)}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ç¿»è¯‘ç»“æœï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—è¯´æ˜ï¼‰ï¼š
{{
    "translations": [
        {{"id": IDæ•°å­—, "translation": "ç¿»è¯‘å†…å®¹"}},
        ...
    ]
}}"""

    try:
        completion = client.chat.completions.create(
            model="deepseek/deepseek-v3.1-terminus",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ¸¸æˆç¿»è¯‘ä¸“å®¶ï¼Œæ“…é•¿å°†æ—¥æ–‡æ¸¸æˆæ–‡æœ¬ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ç¿»è¯‘ç»“æœã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=0.3,
        )
        
        # è°ƒè¯•ï¼šæ£€æŸ¥è¿”å›ç±»å‹
        print(f"DEBUG - completion ç±»å‹: {type(completion)}")
        print(f"DEBUG - completion å†…å®¹: {completion}")
        
        # è·å–å›å¤å†…å®¹
        if isinstance(completion, str):
            # å¦‚æœç›´æ¥è¿”å›å­—ç¬¦ä¸²ï¼Œå°±ç”¨è¿™ä¸ªå­—ç¬¦ä¸²
            content = completion
        else:
            # æ ‡å‡† OpenAI å“åº”æ ¼å¼
            content = completion.choices[0].message.content
        
        # å°è¯•æå– JSONï¼ˆå¤„ç†å¯èƒ½çš„ markdown ä»£ç å—ï¼‰
        content = content.strip()
        if content.startswith("```json"):
            content = content[7:]
        if content.startswith("```"):
            content = content[3:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        # è§£æ JSON
        result_json = json.loads(content)
        result = TranslationBatch(**result_json)
        
        # éªŒè¯è¿”å›æ•°é‡
        if len(result.translations) != len(items):
            raise ValueError(
                f"ç¿»è¯‘æ•°é‡ä¸åŒ¹é…ï¼å‘é€äº† {len(items)} æ¡ï¼Œæ”¶åˆ°äº† {len(result.translations)} æ¡"
            )
        
        # éªŒè¯ ID åŒ¹é…
        for i, (item, trans) in enumerate(zip(items, result.translations)):
            if item["id"] != trans.id:
                raise ValueError(
                    f"ç¬¬ {i+1} æ¡ ID ä¸åŒ¹é…ï¼æœŸæœ› {item['id']}ï¼Œå¾—åˆ° {trans.id}"
                )
        
        return [trans.translation for trans in result.translations]
        
    except Exception as e:
        print(f"ç¿»è¯‘å‡ºé”™: {e}")
        raise


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ API Key
    if not API_KEY:
        print("é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("ä¾‹å¦‚: export OPENAI_API_KEY='your-api-key'")
        return
    
    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
    client_kwargs = {"api_key": API_KEY}
    if API_BASE:
        client_kwargs["base_url"] = API_BASE
        print(f"ä½¿ç”¨è‡ªå®šä¹‰ API Base: {API_BASE}")
    
    client = OpenAI(**client_kwargs)

    glossary: List[Dict[str, Any]] = []
    if Path(GLOSSARY_FILE).exists():
        print(f"åŠ è½½æœ¯è¯­è¡¨ {GLOSSARY_FILE}...")
        glossary = load_glossary_terms(GLOSSARY_FILE)
        print(f"æœ¯è¯­æ¡ç›®: {len(glossary)}")
    else:
        print(f"æœªæ‰¾åˆ°æœ¯è¯­è¡¨ {GLOSSARY_FILE}ï¼Œå°†ä¸ä½¿ç”¨æœ¯è¯­æç¤º")
    
    # åŠ è½½æ•°æ®
    print(f"æ­£åœ¨åŠ è½½ {INPUT_FILE}...")
    data = load_json(INPUT_FILE)
    print(f"å…±åŠ è½½ {len(data)} æ¡æ•°æ®")
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¿»è¯‘æ–‡ä»¶ï¼Œå¦‚æœæœ‰åˆ™ä»æ–­ç‚¹ç»§ç»­
    start_index = 0
    translated_data = []
    
    if Path(OUTPUT_FILE).exists():
        print(f"å‘ç°å·²å­˜åœ¨çš„ç¿»è¯‘æ–‡ä»¶ {OUTPUT_FILE}ï¼Œä»æ–­ç‚¹ç»§ç»­...")
        translated_data = load_json(OUTPUT_FILE)
        start_index = len(translated_data)
        print(f"å·²ç¿»è¯‘ {start_index} æ¡ï¼Œå°†ä»ç¬¬ {start_index + 1} æ¡ç»§ç»­")
    
    # åˆ†æ‰¹ç¿»è¯‘
    total = len(data)
    for i in range(start_index, total, BATCH_SIZE):
        batch = data[i:i + BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1
        total_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE
        
        print(f"\næ­£åœ¨ç¿»è¯‘ç¬¬ {batch_num}/{total_batches} æ‰¹ (ç¬¬ {i+1}-{min(i+BATCH_SIZE, total)} æ¡)...")
        
        try:
            translations = translate_batch(client, batch, glossary)
            
            # æ·»åŠ ç¿»è¯‘å­—æ®µ
            for item, translation in zip(batch, translations):
                translated_item = item.copy()
                translated_item["translation"] = translation
                translated_item["stage"] = 1  # æ ‡è®°ä¸ºå·²ç¿»è¯‘é˜¶æ®µ
                translated_data.append(translated_item)
            
            # æ¯æ‰¹æ¬¡ä¿å­˜ä¸€æ¬¡ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±ï¼‰
            save_json(translated_data, OUTPUT_FILE)
            print(f"âœ“ å®Œæˆï¼Œå·²ä¿å­˜åˆ° {OUTPUT_FILE}")
            
        except Exception as e:
            print(f"âœ— æ‰¹æ¬¡ç¿»è¯‘å¤±è´¥: {e}")
            print(f"å·²ä¿å­˜å‰ {len(translated_data)} æ¡ç¿»è¯‘ç»“æœåˆ° {OUTPUT_FILE}")
            print("æ‚¨å¯ä»¥ä¿®å¤é—®é¢˜åé‡æ–°è¿è¡Œè„šæœ¬ï¼Œå°†è‡ªåŠ¨ä»æ–­ç‚¹ç»§ç»­")
            return
    
    print(f"\nğŸ‰ å…¨éƒ¨ç¿»è¯‘å®Œæˆï¼")
    print(f"è¾“å…¥æ–‡ä»¶: {INPUT_FILE} ({len(data)} æ¡)")
    print(f"è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE} ({len(translated_data)} æ¡)")


if __name__ == "__main__":
    main()
